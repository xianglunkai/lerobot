{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo \"üéØ ÂºÄÂßãËÆ≠ÁªÉ...\"\n",
    "!python3 -m lerobot.scripts.train \\\n",
    "    --dataset.root=./dataset/qnbot_data1 \\\n",
    "    --dataset.repo_id=bradley/qnbot_cherry_transfer_20250705 \\\n",
    "    --policy.type=act \\\n",
    "    --policy.repo_id=bradley/qnbot_cherry_transfer_act \\\n",
    "    --output_dir=outputs/qnbot_cherry_transfer_act \\\n",
    "    --batch_size=16 \\\n",
    "    --steps=100000 \\\n",
    "    --policy.device=cuda \\\n",
    "    --wandb.enable=true \\\n",
    "    --wandb.mode=offline \\\n",
    "    --wandb.project=lerobot_qnbot \\\n",
    "    --wandb.entity=breadlee1024 \\\n",
    "    --wandb.notes=\"QnBotÊ®±Ê°É‰º†ÈÄí‰ªªÂä° - Âè≥ÊâãÊãøÊ®±Ê°ÉÁé©ÂÖ∑‰º†ÈÄíÁªôÂ∑¶ÊâãÊîæÂà∞ÁôΩÁõòÂ≠êÈáå\" \\\n",
    "    --log_freq=200 \\\n",
    "    --save_freq=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "from lerobot.datasets.utils import dataset_to_policy_features\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "FPS = 30\n",
    "# Dataset parameters\n",
    "import os\n",
    "import lerobot\n",
    "\n",
    "# Get parent directory of the current file\n",
    "\n",
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(lerobot.__file__)))\n",
    "\n",
    "dataset_root = os.path.join(REPO_PATH, \"dataset/qnbot_data1\")\n",
    "\n",
    "repo_id = \"bradley/qnbot_cherry_transfer_20250705\"\n",
    "logging.info(f\"Using LeRobot repo path: {dataset_root}\")\n",
    "\n",
    "# Create  a directory to sotore the training checkpoints\n",
    "output_dir = Path(\"outputs/train/qnbot_cherry_transfer_act\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "logging.info(f\"Using output directory: {output_dir}\")\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Number of offline training steps (we'll only do offline training for this example.)\n",
    "# Adjust as you prefer. 5000 steps are needed to get something worth evaluating.\n",
    "training_steps = 100000\n",
    "log_freq = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: {'observation.state': PolicyFeature(type=<FeatureType.STATE: 'STATE'>, shape=(17,)), 'observation.images.left_wrist': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 480, 640)), 'observation.images.head': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 480, 640)), 'observation.images.right_wrist': PolicyFeature(type=<FeatureType.VISUAL: 'VISUAL'>, shape=(3, 480, 640))}\n",
      "Output features: {'action': PolicyFeature(type=<FeatureType.ACTION: 'ACTION'>, shape=(17,))}\n"
     ]
    }
   ],
   "source": [
    "# When starting from scratch (i.e. not from a pretrained policy), we need to specify 2 things before\n",
    "# creating the policy:\n",
    "#   - input/output shapes: to properly size the policy\n",
    "#   - dataset stats: for normalization and denormalization of input/outputs\n",
    "dataset_metadata = LeRobotDatasetMetadata(repo_id=repo_id, root=dataset_root)\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "from pprint import pformat\n",
    "print(f\"Dataset metadata:\\n{pformat(input_features)}\")\n",
    "print(f\"Output features:\\n{pformat(output_features)}\")\n",
    "logging.info(f\"Input features: {input_features}\")\n",
    "logging.info(f\"Output features: {output_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 2. Dataset Setup\n",
    "# =============================================\n",
    "from lerobot.policies.diffusion.configuration_diffusion import DiffusionConfig\n",
    "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "\n",
    "cfg = DiffusionConfig(input_features=input_features, output_features=output_features)\n",
    "\n",
    "\n",
    "delta_timestamps = {\n",
    "    \"observation.images.head\": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],\n",
    "    \"observation.images.left_wrist\": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],\n",
    "    \"observation.images.right_wrist\": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],\n",
    "    \"observation.state\": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],\n",
    "    \"action\": [i / dataset_metadata.fps for i in cfg.action_delta_indices],\n",
    "}\n",
    "\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=repo_id,\n",
    "    root=dataset_root,\n",
    "    delta_timestamps=delta_timestamps\n",
    ")\n",
    "\n",
    "# repo_ids = [f\"agibotworld/{path.name}\" for path in Path(dataset_path).glob(\"agibotworld/task_*\")]\n",
    "# multi_dataset = MultiLeRobotDataset(\n",
    "#     repo_ids=repo_ids,\n",
    "#     root=dataset_path,\n",
    "#     delta_timestamps=delta_timestamps,\n",
    "#     local_files_only=True\n",
    "# )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=device.type != \"cpu\",\n",
    "    drop_last=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 3. Policy Configuration and Initialization\n",
    "# =============================================\n",
    "cfg.input_shapes = {\n",
    "    \"observation.images.head\": [3, 480, 640],\n",
    "    \"observation.images.left_wrist\": [3, 480, 640],\n",
    "    \"observation.images.right_wrist\": [3, 480, 640],\n",
    "    \"observation.state\": [17],\n",
    "}\n",
    "cfg.input_normalization_modes = {\n",
    "    \"observation.images.head\": \"mean_std\",\n",
    "    \"observation.images.left_wrist\": \"mean_std\",\n",
    "    \"observation.images.right_wrist\": \"mean_std\",\n",
    "    \"observation.state\": \"min_max\",\n",
    "}\n",
    "cfg.output_shapes = {\n",
    "    \"action\": [17],\n",
    "}\n",
    "\n",
    "\n",
    "policy = DiffusionPolicy(cfg, dataset_stats=dataset.meta.stats)\n",
    "#policy = DiffusionPolicy(cfg, dataset_stats=multi_dataset.stats)\n",
    "policy.train()\n",
    "\n",
    "policy.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 loss: 1.204\n",
      "step: 1 loss: 1.403\n",
      "step: 2 loss: 1.125\n",
      "step: 3 loss: 1.057\n",
      "step: 4 loss: 1.064\n",
      "step: 5 loss: 1.005\n",
      "step: 6 loss: 1.015\n",
      "step: 7 loss: 1.018\n",
      "step: 8 loss: 1.023\n",
      "step: 9 loss: 1.025\n",
      "step: 10 loss: 1.009\n",
      "step: 11 loss: 1.014\n",
      "step: 12 loss: 1.016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m----> 8\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {k: (v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      9\u001b[0m         loss, _ \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mforward(batch)\n\u001b[1;32m     10\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m----> 8\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {k: (\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      9\u001b[0m         loss, _ \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mforward(batch)\n\u001b[1;32m     10\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================\n",
    "# 4. Training Loop\n",
    "# =============================================\n",
    "step = 0\n",
    "done = False\n",
    "while not done:\n",
    "    for batch in dataloader:\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        loss, _ = policy.forward(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % log_freq == 0:\n",
    "            print(f\"step: {step} loss: {loss.item():.3f}\")\n",
    "        step += 1\n",
    "        if step >= training_steps:\n",
    "            done = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 5. Save Policy Checkpoint\n",
    "# =============================================\n",
    "policy.save_pretrained(output_path)\n",
    "print(f\"Model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
